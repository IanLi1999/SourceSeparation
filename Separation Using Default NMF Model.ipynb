{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.util\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.io.wavfile import write\n",
    "from librosa.core import icqt\n",
    "import librosa.display\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y ,sr = librosa.load('.`/resource/2-poly.wav')\n",
    "C = librosa.cqt(y, sr=sr, hop_length=64, n_bins=84, bins_per_octave=12)\n",
    "C_n = np.abs(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Examples Ref  \n",
    "```python\n",
    "wav = icqt(C, sr=sr, hop_length=64, res_type='fft')\n",
    "write('after.wav', sr, wav)\n",
    "IPython.display.Audio(data=y, rate=sr)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos  \n",
    "- [x] Check **librosa** official example of [harmonic/percussive separation](https://nbviewer.jupyter.org/github/librosa/librosa/blob/master/examples/LibROSA%20audio%20effects%20and%20playback.ipynb)  \n",
    "- [ ] Check possible solutions to the bottleneck of icqt problem  \n",
    "    - [ ] Manully add virtual part to the matrix  \n",
    "    > Depending on how it would affect the icqt  \n",
    "    - [ ] Try other resample models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_separation(y, sr):\n",
    "    n_components = 2\n",
    "    nmf_model = NMF(n_components=n_components, init='random', max_iter=500, alpha=0, l1_ratio=0.0)\n",
    "    \n",
    "    S_full, phase = librosa.magphase(C)\n",
    "    print(type(S_full[0][0]), type(phase[0][0]))\n",
    "    \n",
    "    W = nmf_model.fit_transform(S_full)\n",
    "    H = nmf_model.components_\n",
    "    print(nmf_model.reconstruction_err_)\n",
    "    \n",
    "    n_W = []\n",
    "    n_H = []\n",
    "    n_S = []\n",
    "    n_C = []\n",
    "    n_wav = []\n",
    "    for i in range(0, n_components):\n",
    "        w = W[:,i:i+1]\n",
    "        h = H[i:i+1, :]\n",
    "        s = np.multiply(w, h)\n",
    "        c = s * phase\n",
    "        wav = icqt(c, sr=sr, hop_length=64)\n",
    "\n",
    "        n_W.append(w)\n",
    "        n_H.append(h)\n",
    "        n_S.append(s)\n",
    "        n_C.append(c)\n",
    "        n_wav.append(wav)\n",
    "    \n",
    "    return n_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_y = y.reshape((16, 5776))\n",
    "n_wav = source_separation(n_y[1])\n",
    "\n",
    "IPython.display.Audio(data=n_wav[0], rate=sr)\n",
    "IPython.display.Audio(data=n_wav[1], rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos\n",
    "[librosa.beat.tempo](https://librosa.github.io/librosa/generated/librosa.beat.tempo.html#librosa.beat.tempo) could be used to detect and estimate tempo.  \n",
    "[librosa.onset.onset_detect](https://librosa.github.io/librosa/generated/librosa.onset.onset_detect.html#librosa.onset.onset_detect) could be used to detect onset.  \n",
    "[librosa.decompose.decompose](https://librosa.github.io/librosa/generated/librosa.decompose.decompose.html#librosa.decompose.decompose) decompose a feature matrix with **scikit-learn** as well.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
